# Multi-Agent Research Platform

ğŸš€ **Enterprise-grade multi-agent research platform** built on Google ADK v1.5.0 with advanced Gemini 2.5 integration, sophisticated orchestration, and comprehensive monitoring capabilities.

[![Platform](https://img.shields.io/badge/Platform-Google%20ADK%20v1.5.0-blue)](https://cloud.google.com/adk)
[![Models](https://img.shields.io/badge/Models-Gemini%202.5-green)](https://ai.google.dev/)
[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://python.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

## ğŸŒŸ Platform Overview

The Multi-Agent Research Platform is a sophisticated, production-ready system featuring intelligent agent orchestration, external service integration, and enterprise-grade monitoring. Built with modern software architecture principles and optimized for both research workflows and scalable deployments.

### âš¡ Key Capabilities

- **ğŸ¤– 9 Specialized LLM Agent Roles** with Gemini 2.5 thinking budgets and structured output
- **ğŸ­ 9 Orchestration Strategies** with intelligent adaptive selection
- **ğŸŒ External Service Integration** via 4 MCP servers (Perplexity, Tavily, Brave, Omnisearch)
- **ğŸ–¥ï¸ Dual Interface Approach** - Streamlit for users, Web debug for developers
- **ğŸ“Š Enterprise Logging** with failure-safe run-based organization
- **âš™ï¸ Multi-Backend Services** supporting in-memory, database, and cloud deployments
- **ğŸ§µ Thread-Safe Operations** with performance tracking and resource management

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interfaces                             â”‚
â”‚  ğŸ¨ Streamlit (Production) â€¢ ğŸ”§ Web Debug â€¢ ğŸŒ REST APIs     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Orchestration Layer                           â”‚
â”‚  ğŸ­ Agent Orchestrator (9 Strategies) â€¢ ğŸ“‹ Task Manager       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Agent System                               â”‚
â”‚  ğŸ¤– LLM Agents (9 roles) â€¢ ğŸ”„ Workflow â€¢ ğŸ¯ Custom           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Service Layer                                â”‚
â”‚  ğŸ’¾ Session â€¢ ğŸ§  Memory â€¢ ğŸ“ Artifact â€¢ ğŸ“Š Logging          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               Integration & Foundation                          â”‚
â”‚  ğŸ”— Google ADK v1.5.0 â€¢ ğŸŒ MCP Servers â€¢ ğŸ”Œ APIs           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+** (3.11+ recommended)
- **UV package manager** or pip
- **Google AI API Key** ([Get it here](https://makersuite.google.com/app/apikey))
- **4GB+ RAM** (8GB+ recommended for multiple agents)

### âš¡ 5-Minute Setup

```bash
# 1. Clone and install
git clone <repository-url>
cd multi-agent-research-platform
uv sync  # Creates .venv automatically

# 2. Configure environment
cp .env.example .env
# Edit .env with your Google API key:
# GOOGLE_API_KEY=your_gemini_api_key_here

# 3. Launch the platform
python src/streamlit/launcher.py  # Production interface (Port 8501)
# OR
python src/web/launcher.py -e debug  # Debug interface (Port 8081)
```

### ğŸ¯ First Research Task

**Via Streamlit Interface (Recommended):**
1. Open http://localhost:8501
2. Create a **Researcher** agent
3. Execute: *"What are the main benefits of renewable energy?"*
4. Watch real-time orchestration and results

**Via REST API:**
```bash
curl -X POST http://localhost:8081/api/v1/orchestration/execute \
  -H "Content-Type: application/json" \
  -d '{
    "task": "Analyze AI applications in healthcare",
    "strategy": "adaptive",
    "priority": "medium"
  }'
```

## ğŸ¤– Agent System

### 9 Specialized LLM Agent Roles

| Agent Role | Primary Capabilities | Best For |
|------------|---------------------|----------|
| ğŸ”¬ **RESEARCHER** | Web search, fact-checking, literature review | Information gathering, source verification |
| ğŸ“Š **ANALYST** | Statistical analysis, trend identification | Data interpretation, forecasting |
| ğŸ”— **SYNTHESIZER** | Information integration, conflict resolution | Multi-source summary, knowledge consolidation |
| ğŸ¯ **CRITIC** | Quality assessment, bias detection | Review, error identification, improvement |
| ğŸ“‹ **PLANNER** | Task breakdown, resource allocation | Project planning, milestone creation |
| ğŸ’¬ **COMMUNICATOR** | Clear communication, presentation | Stakeholder engagement, content adaptation |
| ğŸ¨ **CREATIVE** | Innovation, brainstorming, original content | Creative solutions, ideation |
| ğŸ“ **SPECIALIST** | Deep domain expertise, technical precision | Expert-level analysis, industry insights |
| ğŸŒŸ **GENERALIST** | Cross-domain tasks, general assistance | Versatile support, initial assessment |

### ğŸ­ Orchestration Strategies

```python
# 9 Available Orchestration Strategies
OrchestrationStrategy.ADAPTIVE        # ğŸ§  Intelligent strategy selection (recommended)
OrchestrationStrategy.SINGLE_BEST     # ğŸ† Optimal agent selection
OrchestrationStrategy.PARALLEL_ALL    # âš¡ All capable agents simultaneously
OrchestrationStrategy.CONSENSUS       # ğŸ¤ Multiple agents with consensus building
OrchestrationStrategy.PIPELINE        # ğŸ”„ Sequential processing chain
OrchestrationStrategy.COMPETITIVE     # ğŸ Best result selection
OrchestrationStrategy.SEQUENTIAL      # ğŸ“‹ Step-by-step execution
OrchestrationStrategy.HIERARCHICAL    # ğŸ—ï¸ Lead agent coordination
OrchestrationStrategy.COLLABORATIVE   # ğŸ¤ Real-time agent cooperation
```

### ğŸ§  Advanced Agent Features

- **ğŸ§­ Intelligent Model Selection**: Automatic Gemini 2.5 model selection based on task complexity
- **ğŸ’­ Thinking Budgets**: Enhanced reasoning with configurable thinking time
- **ğŸ“Š Structured Output**: Schema-based responses for complex analysis
- **ğŸ¯ Performance Tracking**: Real-time success rates and execution metrics
- **ğŸ§µ Thread-Safe Registry**: Concurrent agent operations with RLock protection

## ğŸŒ Interface Options

### ğŸ¨ Streamlit Interface (Production UX)
**Target**: Researchers, analysts, business users
**Port**: 8501

**Features:**
- âœ… Intuitive visual agent builder
- âœ… Real-time task progress monitoring  
- âœ… Interactive charts and analytics
- âœ… Export capabilities (JSON, CSV, PDF)
- âœ… Multi-environment support (dev/prod/demo)
- âœ… Light/dark theme switching

```bash
# Start production interface
python src/streamlit/launcher.py -e production

# Development mode with debug features
python src/streamlit/launcher.py -e development
```

### ğŸ”§ Web Debug Interface (Developer Tools)
**Target**: Developers, system administrators
**Port**: 8081

**Features:**
- ğŸ”§ Real-time monitoring dashboards
- ğŸ”§ Agent performance analytics
- ğŸ”§ WebSocket communication testing
- ğŸ”§ API documentation at `/docs`
- ğŸ”§ System health monitoring
- ğŸ”§ Debug tools and log analysis

```bash
# Start debug interface with hot reload
python src/web/launcher.py -e debug --reload

# Production monitoring
python src/web/launcher.py -e production
```

## âš™ï¸ Service Architecture

### Multi-Backend Service Layer

#### ğŸ’¾ Session Service (3 Backend Options)
- **InMemory**: Development and testing
- **Database**: Production SQLite with connection pooling
- **VertexAI**: Cloud-native with ADK integration

#### ğŸ§  Memory Service (3 Backend Options)
- **InMemory**: Basic keyword search
- **Database**: SQLite with FTS5 full-text search
- **VertexAI RAG**: Semantic search with vector embeddings

#### ğŸ“ Artifact Service (4 Backend Options)
- **InMemory**: Development/testing
- **LocalFile**: File system with versioning
- **GCS**: Google Cloud Storage
- **S3**: AWS S3 integration

```bash
# Configure service backends via environment variables
export SESSION_SERVICE_BACKEND=database
export MEMORY_SERVICE_BACKEND=database
export ARTIFACT_SERVICE_BACKEND=local
```

## ğŸŒ External Service Integration

### MCP Server Integration (4 Services)

| Service | Capability | Use Case |
|---------|------------|----------|
| ğŸ§  **Perplexity** | AI-powered research | Advanced analysis and insights |
| ğŸ” **Tavily** | Optimized web search | Fast, relevant web results |
| ğŸ›¡ï¸ **Brave Search** | Privacy-focused search | Secure, private research |
| ğŸŒ **Omnisearch** | Multi-source aggregation | Comprehensive cross-validation |

### Search Strategies
```python
# 8 Available Search Strategies
"ADAPTIVE"           # ğŸ§  Intelligent strategy selection
"HYBRID_VALIDATION"  # âœ… Cross-validate across multiple sources
"QUALITY_OPTIMIZED"  # â­ Best quality results
"SPEED_OPTIMIZED"    # âš¡ Fastest response
"COST_OPTIMIZED"     # ğŸ’° Minimize API costs
"PARALLEL_ALL"       # ğŸ”„ Query all sources simultaneously
"SEQUENTIAL"         # ğŸ“‹ Try sources in order
"SINGLE_BEST"        # ğŸ† Use best single source
```

## ğŸ“Š Enterprise Logging

### Run-Based Logging Architecture

Each execution creates an isolated log directory with comprehensive tracking:

```
logs/runs/TIMESTAMP_INVOCATION-ID/
â”œâ”€â”€ events.jsonl      # ğŸ“Š Machine-readable event stream
â”œâ”€â”€ summary.json      # ğŸ“‹ Run metadata and final status
â”œâ”€â”€ debug.log         # ğŸ” Debug level messages
â”œâ”€â”€ info.log          # â„¹ï¸ Info level messages
â”œâ”€â”€ error.log         # âŒ Error level messages
â””â”€â”€ performance.json  # âš¡ Performance metrics and timings
```

### Key Features
- **ğŸ›¡ï¸ Failure-Safe Operation**: Logs persist even on crashes
- **ğŸ¤– LLM-Ready Formatting**: Structured JSONL events for AI analysis
- **ğŸ“ˆ Performance Tracking**: Built-in metrics collection
- **ğŸ” Real-time Monitoring**: Live log analysis capabilities

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ agents/                # ğŸ¤– Multi-agent system core
â”‚   â”œâ”€â”€ base.py           # Agent registry, capabilities, base classes
â”‚   â”œâ”€â”€ llm_agent.py      # Gemini 2.5 LLM agents (9 roles)
â”‚   â”œâ”€â”€ orchestrator.py   # 9 orchestration strategies
â”‚   â””â”€â”€ factory.py        # Agent creation and team templates
â”œâ”€â”€ config/               # âš™ï¸ Pydantic configuration system
â”‚   â”œâ”€â”€ base.py          # Base config with validation
â”‚   â”œâ”€â”€ gemini_models.py # Gemini 2.5 model selection
â”‚   â””â”€â”€ services.py      # Service configurations
â”œâ”€â”€ services/            # ğŸ”§ Multi-backend service layer
â”‚   â”œâ”€â”€ session.py      # Session management (3 backends)
â”‚   â”œâ”€â”€ memory.py       # Memory service (3 backends)
â”‚   â””â”€â”€ artifact.py     # Artifact handling (4 backends)
â”œâ”€â”€ mcp/                 # ğŸŒ MCP server integration
â”‚   â”œâ”€â”€ orchestrator.py # Multi-source search orchestration
â”‚   â””â”€â”€ servers/        # Specific server implementations
â”œâ”€â”€ platform_logging/   # ğŸ“Š Enterprise logging system
â”‚   â”œâ”€â”€ logger.py       # Run-based logger implementation
â”‚   â””â”€â”€ handlers.py     # Failure-safe file handlers
â”œâ”€â”€ streamlit/          # ğŸ¨ Production user interface
â”‚   â”œâ”€â”€ app.py         # Main Streamlit application
â”‚   â””â”€â”€ launcher.py    # Environment-aware launcher
â””â”€â”€ web/                # ğŸ”§ Debug/monitoring interface
    â”œâ”€â”€ app.py         # FastAPI application
    â”œâ”€â”€ api.py         # REST API endpoints
    â””â”€â”€ launcher.py    # Web interface launcher
```

## ğŸ”§ Configuration

### Required Environment Variables

```bash
# === Google AI Configuration (Required) ===
GOOGLE_API_KEY=your_gemini_api_key_here
GOOGLE_GENAI_USE_VERTEXAI=false  # Local development
GOOGLE_CLOUD_PROJECT=your_project_id  # Cloud deployment

# === Application Settings ===
ENVIRONMENT=development  # development, production, demo, minimal
PORT=8081               # Web debug interface port
STREAMLIT_PORT=8501     # Streamlit interface port
LOG_LEVEL=INFO          # DEBUG, INFO, WARNING, ERROR

# === Service Backend Selection ===
SESSION_SERVICE_BACKEND=database  # inmemory, database, vertexai
MEMORY_SERVICE_BACKEND=database   # inmemory, database, vertexai
ARTIFACT_SERVICE_BACKEND=local    # inmemory, local, gcs, s3

# === Optional MCP Service Keys ===
PERPLEXITY_API_KEY=your_perplexity_key    # Optional
TAVILY_API_KEY=your_tavily_key            # Optional
BRAVE_API_KEY=your_brave_search_key       # Optional

# === Performance Settings ===
MAX_CONCURRENT_AGENTS=5
DEFAULT_TIMEOUT_SECONDS=300
ENABLE_PERFORMANCE_TRACKING=true
```

## ğŸ§ª Testing

### Comprehensive Test Strategy

```bash
# Fast unit tests with mocks (~30 seconds)
python run_tests.py unit

# Service interaction tests (~2 minutes)
python run_tests.py integration

# Full workflow tests (~5 minutes)
python run_tests.py e2e

# Complete test suite (~8 minutes)
python run_tests.py all

# With coverage reporting
python run_tests.py coverage
```

### Test Categories

- **Unit Tests**: Fast, isolated component testing with comprehensive mocks
- **Integration Tests**: Service interaction and API integration testing
- **E2E Tests**: Complete workflow testing with real agent orchestration
- **Performance Tests**: Load testing and scalability validation

## ğŸ“– Usage Examples

### Basic Agent Creation

```python
from src.agents import AgentFactory
from src.agents.llm_agent import LLMRole

# Create agent factory
factory = AgentFactory()

# Create specialized research agent
researcher = factory.create_llm_agent(
    role=LLMRole.RESEARCHER,
    auto_optimize_model=True,  # Intelligent model selection
    enable_thinking=True,      # Enhanced reasoning
    priority_cost=False        # Quality over cost
)

# Execute research task
result = await researcher.execute_task(
    "Analyze renewable energy market trends in 2024"
)

print(f"Success: {result.success}")
print(f"Result: {result.result}")
print(f"Execution time: {result.execution_time_ms}ms")
```

### Advanced Orchestration

```python
from src.agents.orchestrator import AgentOrchestrator, OrchestrationStrategy
from src.agents.base import AgentCapability

# Create orchestrator
orchestrator = AgentOrchestrator()

# Execute with adaptive strategy selection
result = await orchestrator.orchestrate_task(
    task="Comprehensive analysis of AI applications in healthcare",
    strategy=OrchestrationStrategy.ADAPTIVE,  # Auto-selects best approach
    required_capabilities=[
        AgentCapability.RESEARCH,
        AgentCapability.ANALYSIS,
        AgentCapability.SYNTHESIS
    ]
)

print(f"Strategy used: {result.strategy_used}")
print(f"Agents involved: {len(result.agent_results)}")
print(f"Consensus score: {result.consensus_score}")
```

### Predefined Agent Teams

```python
# Create specialized research team
research_team = factory.create_agent_suite(
    suite_type=AgentSuite.RESEARCH_TEAM
)
# Creates: RESEARCHER + ANALYST + SYNTHESIZER

# Create content development team
content_team = factory.create_agent_suite(
    suite_type=AgentSuite.CONTENT_CREATION
)
# Creates: CREATIVE + COMMUNICATOR + CRITIC
```

## ğŸš€ Deployment

### Local Development

```bash
# Start both interfaces simultaneously
python src/web/launcher.py -e debug &
python src/streamlit/launcher.py -e development

# Access:
# - Streamlit Interface: http://localhost:8501
# - Web Debug Interface: http://localhost:8081
```

### Production Deployment

#### Google Cloud Run

```yaml
# cloud-run.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: multi-agent-platform
spec:
  template:
    spec:
      containers:
      - image: gcr.io/PROJECT_ID/multi-agent-platform
        env:
        - name: GOOGLE_GENAI_USE_VERTEXAI
          value: "true"
        - name: ENVIRONMENT
          value: "production"
        resources:
          limits:
            memory: "2Gi"
            cpu: "2"
```

#### Docker

```bash
# Build and run with Docker
docker build -t multi-agent-platform .
docker run -p 8081:8081 -p 8501:8501 --env-file .env multi-agent-platform
```

## ğŸ” Monitoring & Health Checks

### System Health Monitoring

```bash
# Check overall platform health
curl http://localhost:8081/health

# Detailed system status with services
curl http://localhost:8081/api/v1/status

# Agent registry status
curl http://localhost:8081/api/v1/agents/registry/status
```

### Performance Analytics

- **ğŸ“Š Real-time Dashboards**: Live agent activity and performance metrics
- **ğŸ“ˆ Success Rate Tracking**: Agent and orchestration effectiveness
- **â±ï¸ Response Time Monitoring**: Task execution performance
- **ğŸ”„ Resource Usage**: Memory, CPU, and API quota tracking

## ğŸ› Troubleshooting

### Quick Diagnostics

```bash
# Test configuration
python -c "from src.config import get_config; print('Config OK')"

# Test agent creation
python -c "from src.agents import AgentFactory; print('Agents OK')"

# Test services
python -c "from src.services import create_development_services; print('Services OK')"

# Check API key format
echo $GOOGLE_API_KEY | head -c 10  # Should start with "AI"
```

### Common Issues

1. **Import Errors**: Ensure virtual environment is activated
2. **API Key Issues**: Verify Google API key format and quotas
3. **Port Conflicts**: Use alternative ports with `-p` flag
4. **Service Failures**: Check service backend configurations

## ğŸ“š Documentation

Comprehensive documentation is available:

- **[ğŸ“– Quick Start Guide](docs/QUICKSTART_a.md)** - Get started in 5 minutes
- **[ğŸ¤– Agent Documentation](docs/AGENTS_a.md)** - Complete agent system guide
- **[ğŸ—ï¸ Architecture Overview](docs/ARCHITECTURE_a.md)** - System design and patterns
- **[âš™ï¸ Installation Guide](docs/INSTALLATION_a.md)** - Detailed setup instructions
- **[ğŸ”§ Troubleshooting Guide](docs/TROUBLESHOOTING_a.md)** - Common issues and solutions
- **[ğŸ”§ Development Guide](CLAUDE.md)** - Developer documentation and patterns

## ğŸ”® Platform Capabilities

### âœ… Current Features
- **9 LLM Agent Roles** with Gemini 2.5 integration
- **9 Orchestration Strategies** with adaptive selection
- **Multi-Backend Services** (in-memory, database, cloud)
- **Enterprise Logging** with run-based organization  
- **MCP Server Integration** (4 external services)
- **Dual Interface Approach** (Streamlit + Web Debug)
- **Thread-Safe Agent Registry** with performance tracking
- **Comprehensive Testing** (unit, integration, e2e)
- **Intelligent Model Selection** based on task complexity
- **Real-time Monitoring** and health checks

### ğŸ”„ Advanced Features
- **Hot Reload** in development mode
- **Comprehensive Mocking** for external APIs
- **Structured Logging** for debugging
- **Performance Metrics** collection
- **Error Recovery** and resilience patterns
- **Configuration Validation** with Pydantic

## ğŸ¤ Contributing

1. **Follow Established Patterns**: Use the agent and service patterns documented in [CLAUDE.md](CLAUDE.md)
2. **Comprehensive Testing**: Add unit, integration, and e2e tests for new features
3. **Proper Error Handling**: Use `AgentResult` pattern for consistent error propagation
4. **Structured Logging**: Include appropriate logging context for debugging
5. **Documentation Updates**: Update relevant documentation for new features

### Development Setup

```bash
# Install development dependencies
uv sync --dev

# Install pre-commit hooks
pre-commit install

# Run code quality checks
black src/ tests/
isort src/ tests/
ruff check src/ tests/
mypy src/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

For issues and questions:

1. **ğŸ“– Check Documentation**: Review [comprehensive guides](docs/) for solutions
2. **ğŸ” Analyze Logs**: Examine `logs/runs/latest/` for detailed error information
3. **ğŸ§ª Run Diagnostics**: Use provided diagnostic commands for system health
4. **ğŸ› Report Issues**: Open an issue with detailed logs and error information

---

**ğŸš€ Ready to get started?** Follow the [Quick Start Guide](docs/QUICKSTART_a.md) or jump straight into the [5-Minute Setup](#-5-minute-setup) above!